#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
pizza_df = pd.read_csv('/Users/angieryu2202/Desktop/ì „ì²´í”¼ìžìš”ê¸°ìš”ë¦¬ë·°.tsv', sep= '\t')
ëŒ€ì¹˜ë³¸ì _df = pizza_df.loc[pizza_df['location'] == 'ëŒ€ì¹˜ë³¸ì ']
í‰ì´Œí•™ì›ê°€ì _df = pizza_df.loc[pizza_df['location'] == 'í‰ì´Œí•™ì›ê°€ì ']
í™ì„±ì _df = pizza_df.loc[pizza_df['location'] == 'í™ì„±ì ']
ì§„ì£¼ê²½ìƒëŒ€ì _df = pizza_df.loc[pizza_df['location'] == 'ì§„ì£¼ê²½ìƒëŒ€ì ']
í™ëŒ€ìƒìˆ˜ì _df = pizza_df.loc[pizza_df['location'] == 'í™ëŒ€ìƒìˆ˜ì ']
ë¶€ì‚°ë™ì•„ëŒ€ì _df = pizza_df.loc[pizza_df['location'] == 'ë¶€ì‚°ë™ì•„ëŒ€ì ']
ìˆ­ì‹¤ëŒ€ì _df = pizza_df.loc[pizza_df['location'] == 'ìˆ­ì‹¤ëŒ€ì ']
ì¼ì‚°ë¼íŽ˜ìŠ¤íƒ€ì _df = pizza_df.loc[pizza_df['location'] == 'ì¼ì‚°ë¼íŽ˜ìŠ¤íƒ€ì ']
í™”ì„±ë³‘ì ì _df = pizza_df.loc[pizza_df['location'] == 'í™”ì„±ë³‘ì •ì ']
ì¸ì²œêµ¬ì›”ncì _df = pizza_df.loc[pizza_df['location'] == 'ì¸ì²œêµ¬ì›”ncì ']
ì¼ì‚°í›„ê³¡ì _df = pizza_df.loc[pizza_df['location'] == 'ì¼ì‚°í›„ê³¡ì ']
ë…¸ëŸ‰ì§„ì _df = pizza_df.loc[pizza_df['location'] == 'ë…¸ëŸ‰ì§„ì ']
ìˆ˜ì§€êµ¬ì²­ì _df = pizza_df.loc[pizza_df['location'] == 'ìˆ˜ì§€êµ¬ì²­ì ']
ìƒí˜„ì—­ì _df = pizza_df.loc[pizza_df['location'] == 'ìƒí˜„ì—­ì ']
ì„±ë‚¨ìˆ˜ì§„ì—­ì _df = pizza_df.loc[pizza_df['location'] == 'ì„±ë‚¨ìˆ˜ì§„ì—­ì ']
ìˆ˜ì›í–‰ê¶ë™ì _df = pizza_df.loc[pizza_df['location'] == 'ìˆ˜ì›í–‰ê¶ë™ì ']
ë¶€ì‚°ê´‘ë³µì _df = pizza_df.loc[pizza_df['location'] == 'ë¶€ì‚°ê´‘ë³µì ']
ê³ ì–‘ì–´ë¦°ì´ë°•ë¬¼ê´€ì _df = pizza_df.loc[pizza_df['location'] == 'ê³ ì–‘ì–´ë¦°ì´ë°•ë¬¼ê´€ì ']
ë§ˆì´í¬ìž„íŽ™íŠ¸ìŠ¤íŠœë””ì˜¤ì _df = pizza_df.loc[pizza_df['location'] == 'ë§ˆì´í¬ìž„íŽ™íŠ¸ìŠ¤íŠœë””ì˜¤ì ']


# In[2]:


def text_punc_num_remover (df_col_value, df_col_name):
    import string
    from string import digits
    translator = str.maketrans('', '', string.punctuation)
    punc_removed_column = []
    for line in df_col_value:
        punc_removed_column.append(line.translate(translator))
    #print(punc_removed_column)
    remove_digits = str.maketrans('', '', digits)
    globals()[str(df_col_name)+"_punc_num_removed"] = []
    for item in punc_removed_column:
        globals()[str(df_col_name)+"_punc_num_removed"].append(item.translate(remove_digits))
    print("punc_num_removed")

remove_words = ['\n', '|', 'ðŸ–’', '~', ',' , '!', '?', '^', '@', '>', '<', 'ã…¡', 'ðŸ˜€', ';', '.', 'â¤ï¸', 'ðŸ‘', 'ðŸ’•', 'â™¡', 'â¤', 'ðŸ˜ ', 'ðŸ¤’', 'ðŸ˜¡', 'ðŸ¤£','ðŸ¤©','ðŸ¤—', 'ã…‹', 'ã…Ž', 'ã……','ã…‚', 'ã… ', 'ã…œ', 'ðŸ•', 'ðŸ’“', 'ðŸ§¡', 'ðŸ’›', 'ðŸ’š', 'ðŸ’™', 'ðŸ’œ', 'â£ï¸', 'ðŸ’“', 'ðŸ’–', 'ðŸ’—', 'ðŸ’ž']
def spec_charac_remover(remove_words, df_col_name, punc_num_removed_text):
    globals()[str(df_col_name) + "_preprocessed"] = []
    for i in punc_num_removed_text:
        temp = []
        for k in i.split(" "):
            if not any(i for i in remove_words if i in k):
                temp.append(k)
        globals()[str(df_col_name) + "_preprocessed"].append(" ".join(temp))
    print("spec_charac_removed")

def noun_tokenizer(df_col_name, preprocessed_df):
    from konlpy.tag import Komoran
    komoran = Komoran()
    globals()["noun_"+str(df_col_name)] = []
    i=0
    for words in preprocessed_df:
        i += 1
        globals()["noun_" + str(df_col_name)].append(komoran.nouns(words))
        print('row ' + str(i) + ' finished')
    print("noun_tokenized")


# In[3]:


def text_preprocessor(location):
    text_punc_num_remover(globals()[str(location)+"_df"]['content'], str(location))
    spec_charac_remover(remove_words, str(location), globals()[str(location)+"_punc_num_removed"])
    noun_tokenizer(str(location), globals()[str(location) + "_preprocessed"])
    globals()[str(location)+"_df"]['tokenized_abstract']=globals()["noun_"+str(location)]
    globals()[str(location)+"_df"].to_csv('/Users/angieryu2202/Desktop/'+str(location)+"_df.tsv", sep = '\t')


# In[4]:


address_dict = {"ëŒ€ì¹˜ë³¸ì " : "ì„œìš¸ ê°•ë‚¨êµ¬ ì‚¼ì„±ë¡œ 301",
                "í‰ì´Œí•™ì›ê°€ì " : "ê²½ê¸° ì•ˆì–‘ì‹œ ë™ì•ˆêµ¬ í‰ì´ŒëŒ€ë¡œ 131",
                "í™ì„±ì " : "ì¶©ë‚¨ í™ì„±êµ° í™ì„±ì ì•„ë¬¸ê¸¸29ë²ˆê¸¸ 67", 
                "ì§„ì£¼ê²½ìƒëŒ€ì ":"ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ ê°€ì¢Œë™ 868-33",
                "í™ëŒ€ìƒìˆ˜ì ":"ì„œìš¸ ë§ˆí¬êµ¬ ë…ë§‰ë¡œ19ê¸¸ 32",
                "ë¶€ì‚°ë™ì•„ëŒ€ì ":"ë¶€ì‚° ì„œêµ¬ êµ¬ë•ë¡œ 220",
                "ìˆ­ì‹¤ëŒ€ì ":"ì„œìš¸ ë™ìž‘êµ¬ ìƒë„ë¡œ 362-1",
                "ì¼ì‚°ë¼íŽ˜ìŠ¤íƒ€ì ": "ê²½ê¸° ê³ ì–‘ì‹œ ì¼ì‚°ë™êµ¬ ì¤‘ì•™ë¡œ1275ë²ˆê¸¸ 38-5",
                "í™”ì„±ë³‘ì ì ": "ê²½ê¸° í™”ì„±ì‹œ íš¨í–‰ë¡œ 1060",
                "ì¸ì²œêµ¬ì›”ncì ": "ì¸ì²œ ë‚¨ë™êµ¬ ì¸í•˜ë¡œ 485 ë‰´ì½”ì•„ì•„ìš¸ë ›",
                "ì¼ì‚°í›„ê³¡ì ": "ê²½ê¸° ê³ ì–‘ì‹œ ì¼ì‚°ì„œêµ¬ ì¼ì‚°ë¡œ 547",
                "ë…¸ëŸ‰ì§„ì ": "ì„œìš¸ ë™ìž‘êµ¬ ë…¸ëŸ‰ì§„ë¡œ16ê¸¸ 22-1",
                "ìˆ˜ì§€êµ¬ì²­ì ": "ê²½ê¸° ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ í’ë•ì²œë¡œ 135",
                "ìƒí˜„ì—­ì ": "ê²½ê¸° ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ ê´‘êµì¤‘ì•™ë¡œ 305",
                "ì„±ë‚¨ìˆ˜ì§„ì—­ì ": "ê²½ê¸° ì„±ë‚¨ì‹œ ì¤‘ì›êµ¬ ì›í„°ë¡œ 116",
                "ìˆ˜ì›í–‰ê¶ë™ì ": "ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ì •ì¡°ë¡œ892ë²ˆê¸¸ 4",
                "ë¶€ì‚°ê´‘ë³µì ": "ë¶€ì‚° ì¤‘êµ¬ ê´‘ë³µë¡œ97ë²ˆì•ˆê¸¸ 8",
                "ê³ ì–‘ì–´ë¦°ì´ë°•ë¬¼ê´€ì ": "ê²½ê¸° ê³ ì–‘ì‹œ ë•ì–‘êµ¬ í™”ì¤‘ë¡œ 26",
                "ë§ˆì´í¬ìž„íŽ™íŠ¸ìŠ¤íŠœë””ì˜¤ì ": "ì„œìš¸ ê°•ë‚¨êµ¬ ì—­ì‚¼ë¡œ 180"}
for key in address_dict:
    text_preprocessor(key)


# In[5]:


import pandas as pd
pizza_saved_tuple = []
for key in address_dict:
    globals()[str(key)+"_saved_df"] = pd.read_csv('/Users/angieryu2202/Desktop/'+str(key)+"_df.tsv", sep = '\t')
    pizza_saved_tuple.append(globals()[str(key)+"_saved_df"])
pizza_saved_df = pd.concat(pizza_saved_tuple)


# In[6]:


# ì™€ã… ì§„ì§œ ë“œë””ì–´ ë§Œë“¤ì—ˆë‹¤ã…œã…œã…œã…œã…œ
def tfidf_scatter_plotter (abstracts, docu_year):
    import pandas as pd
    import matplotlib.font_manager as fm
    import matplotlib.pyplot as plt
    from matplotlib import rc
    from sklearn.manifold import TSNE
    from sklearn.feature_extraction.text import TfidfVectorizer
    for abstract in abstracts:
        abstract = ' ' + abstract.replace("',","").replace("['","").replace("']","").replace("'","")
    tfidf = TfidfVectorizer(max_features = 100, max_df=0.95, min_df=0)
    #generate tf-idf term-abstracts matrix
    globals()["tfidf_matrix_"+str(docu_year)] = tfidf.fit_transform(abstracts)#size D x V
    
    #tf-idf features
    globals()["tfidf_features_"+str(docu_year)] = tfidf.get_feature_names()
    for tfidf_dict_word in globals()["tfidf_features_"+str(docu_year)]:
        tfidf_dict_word.replace("'","")
    globals()["data_array_"+str(docu_year)] = globals()["tfidf_matrix_"+str(docu_year)].toarray()
    data = pd.DataFrame(globals()["data_array_"+str(docu_year)], columns=globals()["tfidf_features_"+str(docu_year)])
    print(data.shape)
    # TF-IDFë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ ì‚°ì¶œí•˜ì˜€ê³ , ì„ íƒëœ 100ê°œì˜ ë‹¨ì–´ë¥¼ t-SNEë¡œ ì‹œê°í™” í•˜ì˜€ë‹¤. t-SNEëŠ” ê³ ì°¨ì›(100ì°¨ì›)ìƒì— ì¡´ìž¬í•˜ëŠ” ë°ì´í„°ì˜ ìœ ì‚¬ì„±ë“¤ì„ KL-divergenceê°€ ìµœì†Œí™”ë˜ë„ë¡ ì €ì°¨ì›(2ì°¨ì›)ìœ¼ë¡œ ìž„ë² ë”©ì‹œí‚¤ëŠ” ë°©ë²•ì´ë‹¤.
    tsne = TSNE(n_components=2, n_iter=10000, verbose=1)
    print(globals()["data_array_"+str(docu_year)].shape)
    print(globals()["data_array_"+str(docu_year)].T.shape)
    Z = tsne.fit_transform(globals()["data_array_"+str(docu_year)].T)
    print(Z[0:5])
    print('Top words: ',len(Z))


# In[7]:


def tfidf_table_maker(tfidf_matrix, feature_names, data_array, docu_year):
    import pandas as pd
    import operator
    indices = zip(*tfidf_matrix.nonzero())
    globals()["tfidf_dict_"+str(docu_year)] = {}
    for row,column in indices:
        globals()["tfidf_dict_"+str(docu_year)][feature_names[column]] = data_array[row, column]
    globals()["tfidf_dict_"+str(docu_year)] = sorted(globals()["tfidf_dict_"+str(docu_year)].items(), key=lambda x: (-x[1], x[0]))
    globals()["tfidf_dict_df_"+str(docu_year)] = pd.DataFrame(globals()["tfidf_dict_"+str(docu_year)], columns=['keywords','tfidf_score'])
    print(globals()["tfidf_dict_df_"+str(docu_year)].head(30))


# In[8]:


def tfidf_rank_bar_plotter (tfidf_df, tfidf_score, keywords, docu_year):
    import matplotlib.pyplot as plt
    from matplotlib import rc
    import numpy as np
    rc('font', family='AppleGothic')
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams["font.size"] = 12
    plt.rcParams["figure.figsize"] = (20,15)
    plt.ylabel('Keyword',rotation=90)
    plt.xlabel('TF-IDF Score')
    tfidf_df = tfidf_df.sort_values(by = str(tfidf_score), ascending=True)
    y_pos = np.arange(len(tfidf_df[-30:].keywords))
    # Create horizontal bars
    plt.barh(y_pos, tfidf_df[-30:].tfidf_score, color='#86bf91')
    # Create names on the y-axis
    plt.yticks(y_pos, tfidf_df[-30:].keywords)
    plt.title('Pizza '+docu_year+' TF-IDF Score Rank')
    plt.savefig('/Users/angieryu2202/Desktop/'+docu_year+'_tfidf_rank_barplot.png', bbox_inches='tight')


# In[9]:


for key in address_dict:
    try:
        globals()[str(key)+"_nouns"] = globals()[str(key)+"_saved_df"]['tokenized_abstract']
        tfidf_scatter_plotter(globals()[str(key)+"_nouns"], str(key))
        tfidf_table_maker(globals()["tfidf_matrix_"+str(key)], globals()["tfidf_features_"+str(key)], globals()["data_array_"+str(key)], str(key))
        tfidf_rank_bar_plotter(globals()["tfidf_dict_df_"+str(key)], 'tfidf_score', 'keywords', str(key))
    except:
        pass


# In[ ]:




